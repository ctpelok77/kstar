Weitere Fragen zu Stefans GA-Code:

 * Im Paper steht, dass kein Crossover verwendet wurde, aber im Code
   sieht es so aus, als würde das Standard-Crossover (1-Point)
   verwendet werden (mit p = 0.01). Kann man da mehr zu sagen?

 * Auch bei den anderen Parametern (Populationsgröße, Anzahl
   Generationen, Mutationswahrscheinlichkeit) ist nicht ganz klar, was
   tatsächlich im Paper verwendet wurde.

 * Im BP-Init sieht es ein bisschen so aus, als hätte maxSize einen
   Off-by-One-Fehler: es wird nicht 2^{options.maxPatterns} berechnet,
   sondern 2^{options.maxPatterns - 1}.

 * Es sieht so aus, als würde immer das beste Individuum über alle
   Generationen zurückgeliefert werden, nicht das beste der letzten
   Generation.

 * Außerdem ist wohl das Elitism-Flag gesetzt, was wohl bedeutet, dass
   das beste Individuum immer in die nächste Generation übernommen
   wird. (?)

 * Der Bin-Packing-Algorithmus sieht nach Next Fit aus.

 * Es sieht so aus, als würde bei der Erzeugung der initialen Patterns
   versucht, zu jeder Variable auch die kausalen Nachbarn (in beide
   Kantenrichtungen im Causal Graph und nach derjenigen Definition von
   Causal Graph, die auch Effekt-Effekt-Kanten einschließt)
   hinzuzufügen, allerdings nicht rekursiv. Wenn nicht mehr alle
   Nachbarn der aktuellen Variable ins aktuelle Pattern reinpassen,
   werden sie einfach gemeinsam ins nächste Pattern geworfen (ohne
   dort noch mal ihre Nachbarn zu berücksichtigen).

   => Von Causal Graphs ist im Paper nicht die Rede. Wurde das erst
   *nach* dem Paper eingebaut?

 * Wieviele Patterns erzeugt er?
 => So viele wie nötig sind, um alle Variablen abzudecken.

* TODO: Noch mal nachsehen, ob zu den diversen Parametereinstellungen was im Paper steht.

* TODO: Additivitätsfrage

=> Siehe PDB-Code -- der GA-Code tut da wohl nichts Besonderes.

  "How exactly do you deal with the case that two variables that are
   in different patterns are affected by the same operator? Do you
   assign the whole cost of the operator to the *first* pattern in the
   collection, and zero to the later ones?"

* Wie funktioniert die Mutation?

  Mit Wahrscheinlichkeit epsilon = 0.0002 (= onlyEnlargeMinim)
  wird MinimizeMutator aufgerufen, mit derselben W-keit
  EnlargementMutator; ansonsten FlipMutator.

  * FlipMutator:

  Wenn die erwartete Anzahl Flips < 1 ist, dann entscheide für jedes
  Bit zufällig, ob es von 0 auf 1 geflippt werden soll oder nicht (mit
  der gegebenen Mutationsrate).

  Wenn sie >= 1 ist, dann runde ab auf die nächste ganze Zahl k und
  wähle zufällig (mit Zurücklegen) k Positionen, die geflippt werden.

  * MinimizeMutator

  Entfernt schlechtestes Pattern anhand der Durchschnitts-PDB-Werte,
  die auch für die Selektion verwendet werden. (Aufpassen mit
  Additivität: die hinteren Patterns haben vermutlich 0-Kosten bei
  vorher schon "verbrauchten" Operatoren.)

  Wenn mehrere Patterns gleich schlecht sind, verliert das, das als
  erstes in der Reihenfolge auftaucht.

  * EnlargementMutator

  Erzeuge ein neues Pattern unterhalb der Maximalgröße und füge es ein.

  Algorithmus: betrachte alle Variablen in der gegebenen Reihenfolge
  (d.h. ohne Randomisierung) und füge die aktuelle Variable immer dann
  ein, wenn sie noch reinpasst und bisher in keinem Pattern auftaucht.

  (Wenn keine unbenutzte Variable existiert oder die unbenutzten
  Variablen alle schon für sich allein zu groß sind, dann passiert
  nichts.)

* TODO: Wurde das für das Paper auch genauso verwendet?

(Dort ist nur von dem FlipMutator die Rede.)

* Wie funktioniert die objective function?

Wenn sich zwei Patterns überlappen, wird 0 zurück geliefert.

Wenn ein Pattern zu groß ist, wird 0 zurück geliefert.

Dijkstra-Algorithmus zur Berechnung der PDB-Qualität ignoriert
unerreichbare Zustände, d.h. der Durchschnittswert ist der
Durchschnitt *über alle erreichbaren Zustände*. (Nicht erreichbare
werden also so betrachtet als existierten sie nicht.)

(Wenn mehr als 300 Sekunden für eine einzelne PDB-Berechnung
verbraucht werden, werden alle verbleibenenden Zustände so betrachtet,
als hätten sie den höchsten bisher erreichten h-Wert als h-Wert.)

Ansonsten tut die Evaluationsfunktion das, was man erwarten sollte.

* Wie wird die Fitness daraus berechnet und wie funktoniert die Selektion?

Es werden die Defaults verwendet: GARouletteWheelSelector und
GALinearScaling, was bedeutet, dass die Evaluationswerte e nach der
Formel f = a * e + b in Fitness-Werte umgerechnet werden ("a und b
werden wie in Goldbergs Buch berechnet").

(Details müsste man wohl im Buch oder im Code nachsehen.)

Roulette-Wheel-Selection funktioniert vermutlich so wie besprochen;
könnte man auch noch mal im Code nachsehen.

* GA macht Selektion *vor* Crossover und Mutation.
